{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marina/anaconda/lib/python3.7/site-packages/mpl_toolkits/axes_grid/__init__.py:12: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
      "  obj_type='module')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "import pandas\n",
    "import pyeeg\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "from numpy import zeros, floor, log10, log, mean, array, sqrt, vstack, cumsum, ones, log2, std\n",
    "import scipy.stats as sp\n",
    "from spectrum import *\n",
    "import numpy.fft\n",
    "from numpy.fft import fft\n",
    "from numpy.linalg import svd, lstsq\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import mne.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n",
    "          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n",
    "          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Variance','Mean of Vertex to Vertex Slope','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower',\n",
    "          'Autro Regressive Mode Order 3 Coefficients for each channel ->']\n",
    "channel = ['ch1','ch2','ch3','ch4','ch5','ch6','ch7','ch8','ch9','ch10','ch11','ch12','ch13','ch14','ch15']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hjorth Parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_diff(X):\n",
    "    D = []\n",
    "    for i in range(1,len(X)):\n",
    "        D.append(X[i]-X[i-1])\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth2(X, D = None):\n",
    "\n",
    "    \n",
    "    if D is None:\n",
    "        D = first_order_diff(X)\n",
    "    \n",
    "    D.insert(0, X[0]) # pad the first difference\n",
    "    D = array(D)\n",
    "    n = len(X)\n",
    "    M2 = float(sum(D ** 2)) / n\n",
    "    TP = sum(array(X) ** 2)\n",
    "    M4 = 0;\n",
    "    for i in range(1, len(D)):\n",
    "        M4 += (D[i] - D[i - 1]) ** 2\n",
    "        M4 = M4 / n\n",
    "\n",
    "    return sqrt(M2 / TP), sqrt(float(M4) * TP / M2 / M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_power(X,Band,Fs):\n",
    "\n",
    "\n",
    "    C = fft(X)\n",
    "    C = abs(C)\n",
    "    Power =zeros(len(Band))\n",
    "    for Freq_Index in range(0,len(Band)-1):\n",
    "        Freq = Band[Freq_Index]\n",
    "        Next_Freq = Band[Freq_Index+1]\n",
    "        Power[Freq_Index] = sum(C[int(floor(Freq/Fs*len(X))):int(floor(Next_Freq/Fs*len(X)))])\n",
    "    Power_Ratio = Power/sum(Power)\n",
    "    return Power, Power_Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis , 2nd Diff Mean, 2nd Diff Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) # Saving the mean of array i\n",
    "        std_i = np.std(i) # Saving the standard deviation of array i\n",
    "        t = 0.0\n",
    "        for j in i:\n",
    "            t += (pow((j-mean_i)/std_i,4)-3)\n",
    "        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n",
    "        output[k] = kurtosis_i # Saving the kurtosis in the array created\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##----------------------------------------- End Kurtosis Function ----------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMean(Absolute difference) Function ------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] --------------- ##\n",
    "##-------------------  -- [ Output: 1D array (2ndDiffMean values for each channel)] ----------##\n",
    "\n",
    "def secDiffMean(a):\n",
    "    b = a # Extracting the data of the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    for i in b:\n",
    "        t = 0.0\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        for j in range(len(i)-2):\n",
    "            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n",
    "        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n",
    "##------------------------------------- End 2ndDiffMean Function----- -------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMax Function(Absolute difference) --------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] -----------------##\n",
    "##--------------------- [ Output: 1D array (2ndDiffMax values for each channel)] --------------##\n",
    "\n",
    "def secDiffMax(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    t = 0.0\n",
    "    for i in b:\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "            \n",
    "        t = temp1[1] - temp1[0]\n",
    "        for j in range(len(i)-2):\n",
    "            if abs(temp1[j+1]-temp1[j]) > t :\n",
    "            \tt = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n",
    "\n",
    "        output[k] = t # Storing the 2nd Diff Max for channel k\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of Varaition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_var(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        mean_i = np.mean(i) #Saving the mean of array i\n",
    "        std_i = np.std(i) #Saving the standard deviation of array i\n",
    "        output[k] = std_i/mean_i #computing coefficient of variation\n",
    "        k=k+1\n",
    "    return np.sum(output)/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Skewness , 1st Difference Mean, 1st Difference Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(arr):\n",
    "    data = arr \n",
    "    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0 #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(skew_array)/14\n",
    "\n",
    "\n",
    "def first_diff_mean(arr):\n",
    "    data = arr \n",
    "    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0 #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        sum=0.0#initializing the sum at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "           \n",
    "        diff_mean_array[index]=sum/(len(i)-1)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_mean_array)/14\n",
    "\n",
    "\n",
    "def first_diff_max(arr):\n",
    "    data = arr \n",
    "    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n",
    "    index = 0 #current cell position in the output array\n",
    "   \n",
    "    for i in data:\n",
    "        max=0.0#initializing at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "            if first_diff[j]>max: \n",
    "                max=first_diff[j] # finding the maximum of the first differences\n",
    "        diff_max_array[index]=max\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_max_array)/14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted Wavelet transform\n",
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    #For each channel I compute the discret wavelet transform\n",
    "    for i in range(14):\n",
    "        cA,cD=pywt.dwt(epoch[i][:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    #I make the mean for each channel\n",
    "    for x in range(14):   \n",
    "        cA_mean.append(np.mean(cA_values[x]))\n",
    "        cA_std.append(np.std(cA_values[x]))\n",
    "        cA_Energy.append(np.sum(np.square(cA_values[x])))\n",
    "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
    "        cD_std.append(np.std(cD_values[x]))\n",
    "        cD_Energy.append(np.sum(np.square(cD_values[x])))\n",
    "        Entropy_D.append(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x]))))\n",
    "        Entropy_A.append(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))\n",
    "    return np.sum(cA_mean)/14,np.sum(cA_std)/14,np.sum(cD_mean)/14,np.sum(cD_std)/14,np.sum(cA_Energy)/14,np.sum(cD_Energy)/14,np.sum(Entropy_A)/14,np.sum(Entropy_D)/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Mean of Vertex to Vertex Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c\n",
    "\n",
    "#first_diff(s)\n",
    "\n",
    "def slope_mean(p):\n",
    "    b = np.array(p) #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]\n",
    "        t_max = argrelextrema(x, np.greater)[0]\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]\n",
    "        t_min = argrelextrema(x, np.less)[0]\n",
    "        t = np.concatenate((t_max,t_min),axis=0)\n",
    "        t.sort()#sort on the basis of time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q]         \n",
    "        output[k] = np.mean(res) \n",
    "        k=k+1\n",
    "    return np.sum(output)/14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def slope_var(p):\n",
    "    b = np.array(p) #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for i in b:\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n",
    "        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n",
    "        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n",
    "        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n",
    "        t.sort() #sorting according to time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n",
    "    \n",
    "        output[k] = np.var(res) \n",
    "        k=k+1#counting k\n",
    "    return np.sum(output)/14\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT features(Max Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def maxPwelch(data_win,Fs):\n",
    " \n",
    "    \n",
    "    BandF = [0.1, 3, 7, 12, 30]\n",
    "    PMax = np.zeros([14,(len(BandF)-1)])\n",
    "    \n",
    "    for j in range(14):\n",
    "        f,Psd = signal.welch(data_win[j], Fs)\n",
    "        \n",
    "        for i in range(len(BandF)-1):\n",
    "            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n",
    "            PMax[j,i] = np.max(Psd[fr])\n",
    "    \n",
    "    return np.sum(PMax[:,0])/14,np.sum(PMax[:,1])/14,np.sum(PMax[:,2])/14,np.sum(PMax[:,3])/14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shanon Entropy and Entropy Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_entropy(Power_Ratio):\n",
    "\n",
    "    Spectral_Entropy = 0\n",
    "    for i in range(0, len(Power_Ratio) - 1):\n",
    "        Spectral_Entropy += Power_Ratio[i] * log(Power_Ratio[i])\n",
    "    Spectral_Entropy /= log(len(Power_Ratio))\t# to save time, minus one is omitted\n",
    "    return -1 * Spectral_Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(Template, Scroll, Distance):\n",
    "\n",
    "\n",
    "\tfor i in range(0,  len(Template)):\n",
    "\t\t\tif abs(Template[i] - Scroll[i]) > Distance:\n",
    "\t\t\t     return False\n",
    "\treturn True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Yule Walker Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autogressiveModelParameters(epoch):\n",
    "    feature = []\n",
    "    #Order 11 for the autoregressive model, why?\n",
    "    for i in range(14):\n",
    "        coeff, sig = alg.AR_est_YW(np.array(epoch[i]), 11,)\n",
    "        feature.append(coeff)\n",
    "    \n",
    "     \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Burg Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels):\n",
    "    feature = []\n",
    "    feature1 = []\n",
    "    model_order = 3\n",
    "    for i in range(14):\n",
    "        AR, rho, ref = arburg(labels[i], model_order)\n",
    "        feature.append(AR);\n",
    "    for j in range(14):\n",
    "        for i in range(model_order):\n",
    "            feature1.append(feature[j][i])\n",
    "\n",
    "    return feature1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hurst exponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst(X):\n",
    "\n",
    "\tN = len(X)\n",
    "    \n",
    "\tT = array([float(i) for i in range(1,N+1)])\n",
    "\tY = cumsum(X)\n",
    "\tAve_T = Y/T\n",
    "\t\n",
    "\tS_T = zeros((N))\n",
    "\tR_T = zeros((N))\n",
    "\tfor i in range(N):\n",
    "\t\tS_T[i] = std(X[:i+1])\n",
    "\t\tX_T = Y - T * Ave_T[i]\n",
    "\t\tR_T[i] = max(X_T[:i + 1]) - min(X_T[:i + 1])\n",
    "    \n",
    "\tR_S = R_T / S_T\n",
    "\tR_S = log(R_S)\n",
    "\tn = log(T).reshape(N, 1)\n",
    "\tH = lstsq(n[1:], R_S[1:])[0]\n",
    "\treturn H[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the data (1rst record), creating an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pandas.read_csv(\"/home/marina/Documents/DTU/Advanced machine learning/Project/recordings_csv/\"+\"1_0.csv\")\n",
    "df =DataFrame(file)\n",
    "\n",
    "\n",
    "#Selecting first row\n",
    "#df.iloc[0,2]\n",
    "#print(df['0'])\n",
    "#df[1]\n",
    "channels = []\n",
    "for j in range(0,14):\n",
    "    ch = []\n",
    "    channels.append(ch)\n",
    "\n",
    "#Creating an array of arrays with the data from each channel\n",
    "for j in range(0,14):\n",
    "    for i in range(1,23041):\n",
    "        channels[j].append(df.iloc[j,i])\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features\n",
    "mobility = []\n",
    "complexity = []\n",
    "skewness_list = []\n",
    "hurst_list = []\n",
    "\n",
    "#Features that are computed per channel (each feature has 14 components, one per channel)\n",
    "for j in range(0,14):\n",
    "    mobility.append(hjorth2(channels[j])[0])\n",
    "    complexity.append(hjorth2(channels[j])[1])\n",
    "    skewness_list.append(skewness(channels[j]))\n",
    "    #hurst_list.append(hurst(channels[j]))\n",
    "    \n",
    "autoregressive_burg =autogressiveModelParametersBurg(channels)\n",
    "#Per cada canal en tinc 3\n",
    "autoregressive= autogressiveModelParameters(channels)\n",
    " #Features that are not computed per channel, but per epoch\n",
    "\n",
    "#Shannon entropy\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marina/anaconda/lib/python3.7/site-packages/nitime/utils.py:980: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  complex_result = (np.issubdtype(in1.dtype, np.complex) or\n",
      "/home/marina/anaconda/lib/python3.7/site-packages/nitime/utils.py:981: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  np.issubdtype(in2.dtype, np.complex))\n",
      "/home/marina/anaconda/lib/python3.7/site-packages/scipy/fftpack/basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    }
   ],
   "source": [
    "Band = [0.1, 3, 7, 12, 30]\n",
    "a = first_diff_mean(channels)\n",
    "b = first_diff_max(channels)\n",
    "kurt = kurtosis(channels)\n",
    "secdiffmean = secDiffMean(channels)\n",
    "secdiffmax = secDiffMax(channels)\n",
    "coef_variation = coeff_var(channels)\n",
    "slopemean = slope_mean(channels)\n",
    "slopevar = slope_var(channels)\n",
    "wavelet_features_list = (wavelet_features(channels))\n",
    "w1 = wavelet_features_list[0]\n",
    "w2 = wavelet_features_list[1]\n",
    "w3 = wavelet_features_list[2]\n",
    "w4 = wavelet_features_list[3]\n",
    "w5 = wavelet_features_list[4]\n",
    "w6 = wavelet_features_list[5]\n",
    "w7 = wavelet_features_list[6]\n",
    "w8 = wavelet_features_list[7]\n",
    "#Per cada canal en tinc 3\n",
    "\n",
    "maxPwelch_list = maxPwelch(channels,256)\n",
    "welch1 = maxPwelch_list[0]\n",
    "welch2 = maxPwelch_list[1]\n",
    "welch3 = maxPwelch_list[2]\n",
    "welch4 = maxPwelch_list[3]\n",
    "binpower, binratio = bin_power(channels[0],Band, 256)\n",
    "power1 = binpower[0]\n",
    "power2 = binpower[1]\n",
    "power3 = binpower[2]\n",
    "power4 = binpower[3]\n",
    "ratio1= binratio[0]\n",
    "ratio2 = binratio[1]\n",
    "ratio3 = binratio[2]\n",
    "ratio4 = binratio[3]\n",
    "\n",
    "spec_entropy = spectral_entropy(binratio)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the features into a csv (the ones that do not depend on the channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_features = [a,b,kurt,secdiffmean,secdiffmax,coef_variation,slopemean,slopevar,w1,w2,w3,w4,w5,w6,w7,w8,welch1,welch2,welch3,welch4,power1,power2,power3,power4,ratio1,ratio2,ratio3,ratio4,spec_entropy]\n",
    "name_features = ['first_diff_mean','first_diff_max','kurtosis','sec_diff_mean','sec_diff_max','coef_variation','slopemean','slopevar','w1','w2','w3','w4','w5','w6','w7','w8','welch1','welch2','welch3','welch4','power1','power2','power3','power4','ratio1','ratio2','ratio3','ratio4','spec_entropy']\n",
    "\n",
    "df = DataFrame(array_features)\n",
    "\n",
    "df.rename(index={0:'first_diff_mean',1:'first_diff_max',2:'kurtosis',3:'sec_diff_mean',4:'sec_diff_max',5:'coef_variation',6:'slopemean',7:'slopevar',8:'w1',9:'w2',10:'w3',11:'w4',12:'w5',13:'w6',14:'w7',15:'w8',16:'welch1',17:'welch2',18:'welch3',19:'welch4',20:'power1',21:'power2',22:'power3',23:'power4',24:'ratio1',25:'ratio2',26:'ratio3',27:'ratio4',28:'spec_entropy'}, inplace=True)\n",
    "df.to_csv(\"features_per_recording_no_channel.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the features per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([mobility, complexity, skewness_list])\n",
    "transpose = data.transpose()\n",
    "df2 = DataFrame(transpose)\n",
    "df2.rename(index={0:'ch1',1:'ch2',2:'ch3',3:'ch4',4:'ch5',5:'ch6',6:'ch7',7:'ch8',8:'ch9',9:'ch10',10:'ch11',11:'ch12',12:'ch13',13:'ch14'}, inplace=True)\n",
    "df2.columns = ['Mobility','Complexity','skewness']\n",
    "df2.to_csv(\"features_per_channel.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
